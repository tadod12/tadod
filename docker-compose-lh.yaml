# Configure services
services:
  # S3 Storage
  minio:
    container_name: minio
    hostname: minio
    image: 'minio/minio'
    ports:
      - '9000:9000'
      - '9001:9001'
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
      MINIO_DOMAIN: minio
    command: server /data --console-address ":9001"

  minio-job:
    image: 'minio/mc'
    container_name: minio-job
    hostname: minio-job
    entrypoint: |
      /bin/bash -c "
      sleep 5;
      /usr/bin/mc config --quiet host add myminio http://minio:9000 minio minio123 || true;
      /usr/bin/mc mb --quiet myminio/datalake || true;
      "
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
      - AWS_DEFAULT_REGION=us-east-1
      - S3_ENDPOINT=http://minio:9000
      - S3_PATH_STYLE_ACCESS=true
    depends_on:
      - minio

  # Metastore
  hive-metastore:
    container_name: hive-metastore
    hostname: hive-metastore
    build:
      dockerfile: ./docker/hive-metastore/Dockerfile
    image: tadod/lakehouse:hive-metastore-3.1.2
    ports:
      - '9083:9083' # Metastore Thrift
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://postgres:5432/metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://datalake/
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: minio
      S3_SECRET_KEY: minio123
      S3_PATH_STYLE_ACCESS: "true"
    depends_on:
      postgres:
        condition: service_healthy

  # Query Engine
  trino:
    profiles: [ "trino" ]
    container_name: trino
    hostname: trino
    image: "trinodb/trino:425"
    restart: always
    ports:
      - "8889:8889"
    volumes:
      - ./docker/trino/etc-coordinator:/etc/trino
      - ./docker/trino/catalog:/etc/trino/catalog
    depends_on:
      - hive-metastore

  trino-worker:
    profiles: [ "trino-worker" ]
    container_name: trino-worker
    hostname: trino-worker
    image: "trinodb/trino:425"
    restart: always
    volumes:
      - ./docker/trino/etc-worker:/etc/trino
      - ./docker/trino/catalog:/etc/trino/catalog
    depends_on:
      - trino

  spark-master:
    profiles: [ "spark" ]
    build:
      dockerfile: ./docker/spark/Dockerfile
    image: tadod/lakehouse:spark-master
    container_name: spark-master
    hostname: spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      - SPARK_MODE=master
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
      - AWS_DEFAULT_REGION=us-east-1
      - S3_ENDPOINT=http://minio:9000
      - S3_PATH_STYLE_ACCESS=true
    volumes:
      - ./docker/spark/spark-defaults-iceberg.conf:/opt/spark/conf/spark-defaults.conf
    depends_on:
      - minio
      - hive-metastore

  spark-worker-1:
    profiles: [ "spark" ]
    build:
      dockerfile: ./docker/spark/Dockerfile
    image: tadod/lakehouse:spark-worker
    container_name: spark-worker
    hostname: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
      - AWS_DEFAULT_REGION=us-east-1
      - S3_ENDPOINT=http://minio:9000
      - S3_PATH_STYLE_ACCESS=true
    volumes:
      - ./docker/spark/spark-defaults-iceberg.conf:/opt/spark/conf/spark-defaults.conf
    depends_on:
      - spark-master
      - minio
      - hive-metastore

# Configure Network
networks:
  default:
    name: lakehouse
